apiVersion: kubeflow.org/v1
kind: "TFJob"
metadata:
  name: id42-squad-bert-sync-batch32
spec:
  runPolicy:
    cleanPodPolicy: None
  tfReplicaSpecs:

    CHIEF:
      replicas: 1
      template:

        metadata:
          annotations:
            "tensorspot/num_chief": "1"
            "tensorspot/num_worker": "8"
            "tensorspot/net_request": "4125"
            "tensorspot/gpu_limit": "1.0"
            "tensorspot/gpu_request": "1.0"
            "tensorspot/gpu_mem": "17179869184"
            "tensorspot/placement_policy": "tiresias"
            "tensorspot/skewness_level": "7.3"

        spec:
          containers:
          - name: tensorflow
            command: ["/bin/sh", "-c"]
            env:
            - name: ROOT_DATA_DIR
              value: "/data"
            args:
              - |
                JOB=`python /workspace/job_name.py`;
                mkdir -p /result/id42_squad_bert_sync_batch32;
                echo "id42_squad_bert_sync_batch32" > /workspace/model.txt;
                STARTTIME=`date "+%H:%M:%S.%N"`; echo "$STARTTIME" > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_start_time.txt;
                top -d 0.1 -b | grep python > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_cpu.txt &
                python /workspace/nlp_jobs/bert_dist_squad.py --batch_size 4 --num_batches 24  > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_log.txt 2>&1;
                ENDTIME=`date "+%H:%M:%S.%N"`; echo "$ENDTIME" > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_end_time.txt
            ports:
              - containerPort: 2222
                name: tfjob-port
            image: potato4332/nlp-image:0.0.1-beta
            imagePullPolicy: IfNotPresent
            resources:
              requests:
                cpu: 1
                nvidia.com/gpu: 1
              limits:
                cpu: 5
                nvidia.com/gpu: 1
            volumeMounts:
            - mountPath: /result
              name: tfjob-data
            - mountPath: /data
              name: tfjob-dataset
            - mountPath: /dev/shm
              name: shmdir
          volumes:
          - name: tfjob-data
            persistentVolumeClaim:
              claimName: tfjob-data-volume-claim
          - name: tfjob-dataset
            persistentVolumeClaim:
              claimName: tfjob-nfs-dataset-storage-claim
          - name: shmdir
            emptyDir:
              medium: Memory
              sizeLimit: "8G"
          nodeSelector:
            twonode: worker

          schedulerName: tensorspot-scheduler


    WORKER:
      replicas: 7
      template:

        metadata:
          annotations:
            "tensorspot/num_chief": "1"
            "tensorspot/num_worker": "8"
            "tensorspot/net_request": "4125"
            "tensorspot/gpu_limit": "1.0"
            "tensorspot/gpu_request": "1.0"
            "tensorspot/gpu_mem": "17179869184"
            "tensorspot/placement_policy": "tiresias"
            "tensorspot/skewness_level": "7.3"

        spec:
          containers:
          - name: tensorflow
            command: ["/bin/sh", "-c"]
            env:
            - name: ROOT_DATA_DIR
              value: "/data"
            args:
              - |
                JOB=`python /workspace/job_name.py`;
                mkdir -p /result/id42_squad_bert_sync_batch32;
                echo "id42_squad_bert_sync_batch32" > /workspace/model.txt;
                STARTTIME=`date "+%H:%M:%S.%N"`; echo "$STARTTIME" > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_start_time.txt;
                top -d 0.1 -b | grep python > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_cpu.txt &
                python /workspace/nlp_jobs/bert_dist_squad.py --batch_size 4 --num_batches 24 > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_log.txt 2>&1;
                ENDTIME=`date "+%H:%M:%S.%N"`; echo "$ENDTIME" > /result/id42_squad_bert_sync_batch32/id42_squad_bert_sync_batch32_${JOB}_end_time.txt
            ports:
              - containerPort: 2222
                name: tfjob-port
            image: potato4332/nlp-image:0.0.1-beta
            imagePullPolicy: IfNotPresent
            resources:
              requests:
                cpu: 1
                nvidia.com/gpu: 1
              limits:
                cpu: 5
                nvidia.com/gpu: 1
            volumeMounts:
            - mountPath: /result
              name: tfjob-data
            - mountPath: /data
              name: tfjob-dataset
            - mountPath: /dev/shm
              name: shmdir
          volumes:
          - name: tfjob-data
            persistentVolumeClaim:
              claimName: tfjob-data-volume-claim
          - name: tfjob-dataset
            persistentVolumeClaim:
              claimName: tfjob-nfs-dataset-storage-claim
          - name: shmdir
            emptyDir:
              medium: Memory
              sizeLimit: "8G"
          nodeSelector:
              twonode: worker

          schedulerName: tensorspot-scheduler
 