#!/bin/bash

echo "================= Lambda Labs Setup Script ================="
echo "[https://cloud.lambdalabs.com/instances]"
echo ""
echo "ğŸ’¡ Dockerhub ì´ë¯¸ì§€ ë²„ì „ ìµœì¢… ì •ë¦¬ (2025.04.03)"
echo "   NLP: potato4332/nlp-image:0.0.1"
echo "   CV: potato4332/tf2-cpu-docker:0.5.5x"
echo "   CV: potato4332/tf2-gpu-docker:0.4.5x"
echo ""

# ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê´€ë¦¬ì ê¶Œí•œìœ¼ë¡œ ì‹¤í–‰í•˜ëŠ”ì§€ í™•ì¸
if [[ $EUID -ne 0 ]]; then
   echo "ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” sudoë¡œ ì‹¤í–‰í•´ì•¼ í•©ë‹ˆë‹¤."
   echo "ì‚¬ìš©ë²•: sudo ./lambda_labs_setup.sh [master|worker]"
   exit 1
fi

# ë§ˆìŠ¤í„°/ì›Œì»¤ ë…¸ë“œ ì¸ì í™•ì¸
if [ "$#" -ne 1 ]; then
    echo "ë§ˆìŠ¤í„° ë…¸ë“œì¸ì§€ ì›Œì»¤ ë…¸ë“œì¸ì§€ ì§€ì •í•´ì£¼ì„¸ìš”."
    echo "ì‚¬ìš©ë²•: sudo ./lambda_labs_setup.sh [master|worker]"
    exit 1
fi

NODE_TYPE=$1

if [[ "$NODE_TYPE" != "master" && "$NODE_TYPE" != "worker" ]]; then
    echo "ì¸ìëŠ” 'master' ë˜ëŠ” 'worker'ì—¬ì•¼ í•©ë‹ˆë‹¤."
    echo "ì‚¬ìš©ë²•: sudo ./lambda_labs_setup.sh [master|worker]"
    exit 1
fi

echo "ë…¸ë“œ íƒ€ì…: $NODE_TYPE"
echo ""

# ì‚¬ìš©ì í™•ì¸ ìš”ì²­
read -p "ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): " -n 1 -r
echo    # ì¤„ë°”ê¿ˆ
if [[ ! $REPLY =~ ^[Yy]$ ]]; then
    echo "ì„¤ì¹˜ê°€ ì·¨ì†Œë˜ì—ˆìŠµë‹ˆë‹¤."
    exit 1
fi

# ë‹¨ê³„ë³„ ì„¤ì¹˜ í•¨ìˆ˜
install_cuda() {
    echo "====================> CUDA ì„¤ì¹˜ ì¤‘..."
    mkdir -p ~/cuda_install
    cd ~/cuda_install

    echo "í˜„ì¬ ê²½ë¡œ: $(pwd)"

    # CUDA 12.2 ì„¤ì¹˜
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-ubuntu2204.pin
    mv cuda-ubuntu2204.pin /etc/apt/preferences.d/cuda-repository-pin-600
    wget https://developer.download.nvidia.com/compute/cuda/12.2.0/local_installers/cuda-repo-ubuntu2204-12-2-local_12.2.0-535.54.03-1_amd64.deb
    dpkg -i cuda-repo-ubuntu2204-12-2-local_12.2.0-535.54.03-1_amd64.deb
    cp /var/cuda-repo-ubuntu2204-12-2-local/cuda-*-keyring.gpg /usr/share/keyrings/
    apt-get update

    apt-get -y install cuda-toolkit-12-2

    echo 'export PATH=/usr/local/cuda-12.2/bin${PATH:+:${PATH}}' >> ~/.bashrc
    echo 'export LD_LIBRARY_PATH=/usr/local/cuda-12.2/lib64${LD_LIBRARY_PATH:+:${LD_LIBRARY_PATH}}' >> ~/.bashrc

    # í™˜ê²½ë³€ìˆ˜ ì ìš©
    source ~/.bashrc

    # ì„¤ì¹˜ í™•ì¸
    echo "ë“œë¼ì´ë²„ ë²„ì „:"
    cat /proc/driver/nvidia/version
    echo -e "\nGPU ì •ë³´:"
    nvidia-smi
    echo -e "\nCUDA ë²„ì „:"
    nvcc -V

    echo "CUDA ì„¤ì¹˜ ì™„ë£Œ"
}

install_cudnn() {
    echo "====================> cuDNN ì„¤ì¹˜ ì¤‘..."
    # Zlib
    apt-get install -y zlib1g

    # Network Repo Installation for Ubuntu
    cd ~/cuda_install
    wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64/cuda-keyring_1.1-1_all.deb
    dpkg -i cuda-keyring_1.1-1_all.deb

    # Refresh the repository metadata
    apt-get update
    # Install per-CUDA meta-packages
    apt-get -y install cudnn9-cuda-12

    # í™•ì¸
    echo "cuDNN ë²„ì „:"
    cat /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2

    echo "cuDNN ì„¤ì¹˜ ì™„ë£Œ"
}

install_docker() {
    echo "====================> Docker ì„¤ì¹˜ ì¤‘..."
    # Add Docker's official GPG key:
    apt-get update
    apt-get install -y ca-certificates curl
    install -m 0755 -d /etc/apt/keyrings
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc
    chmod a+r /etc/apt/keyrings/docker.asc

    # Add the repository to Apt sources:
    echo \
    "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \
    $(. /etc/os-release && echo "$VERSION_CODENAME") stable" | \
    tee /etc/apt/sources.list.d/docker.list > /dev/null

    apt-get update

    # List the available versions:
    echo "ì‚¬ìš© ê°€ëŠ¥í•œ Docker ë²„ì „:"
    apt-cache madison docker-ce | awk '{ print $3 }' | head -n 5

    # Select the desired version and install:
    VERSION_STRING=5:27.3.1-1~ubuntu.22.04~jammy
    apt-get install -y docker-ce=$VERSION_STRING docker-ce-cli=$VERSION_STRING containerd.io docker-buildx-plugin docker-compose-plugin

    # í™•ì¸
    echo -e "\nDocker ì„¤ì¹˜ í™•ì¸ ì¤‘..."
    docker run hello-world

    echo "Docker ì„¤ì¹˜ ì™„ë£Œ"
}

install_nvidia_docker() {
    echo "====================> nvidia-docker ì„¤ì¹˜ ì¤‘..."
    apt-get update
    apt-get install -y nvidia-container-toolkit

    nvidia-ctk runtime configure --runtime=docker

    # í™•ì¸
    echo "nvidia-docker ì„¤ì • í™•ì¸:"
    cat /etc/docker/daemon.json

    # Docker ì„œë¹„ìŠ¤ ì¬ì‹œì‘
    systemctl restart docker

    # ë²„ì „ í™•ì¸
    echo -e "\nNVIDIA Container Toolkit ë²„ì „:"
    nvidia-ctk --version

    # ì»¨í…Œì´ë„ˆ êµ¬ë™ í…ŒìŠ¤íŠ¸
    echo "NVIDIA Docker ì„¤ì¹˜ ë° í…ŒìŠ¤íŠ¸ ì™„ë£Œ"
}

setup_prerequisites() {
    echo "====================> ì‚¬ì „ ì„¤ì • ë° Swap ë¹„í™œì„±í™” ì¤‘..."
    modprobe br_netfilter

    cat <<EOF | tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF

    cat <<EOF | tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF

    sysctl --system

    # Swap ë¹„í™œì„±í™”
    swapoff -a
    # ì»´í“¨í„° ê»ë‹¤ ì¼œë„ ë‹¤ì‹œ swapoff -a ë˜ë„ë¡ ì„¤ì •
    sed -i.bak -r 's/(.+ swap .+)/#\1/' /etc/fstab

    echo "ì‚¬ì „ ì„¤ì • ë° Swap ë¹„í™œì„±í™” ì™„ë£Œ"
}

install_kubernetes() {
    echo "====================> Kubernetes ì„¤ì¹˜ ì¤‘..."
    cd /home

    mkdir -p tensorspot
    cd tensorspot

    # ì§€ê¸ˆ Lambda Labsì—ì„œ ê³µìœ  ìŠ¤í† ë¦¬ì§€ ì“°ë©´ ì¶©ëŒë‚¨.
    # ê° ë…¸ë“œì—ì„œ ë¡œì»¬ Path ë§Œë“¤ê¸°.
    mkdir -m 777 data
    mkdir -m 777 tfjob

    git clone -b k8s https://github.com/hyunnnchoi/Cloud-init.git

    cd Cloud-init
    git checkout k8s
    chmod -R 777 /home/tensorspot

    cat apt_archives_part_* | tee merged.tar.gz > /dev/null

    mv merged.tar.gz ../archives.tar.gz

    cd ../

    tar -xzf archives.tar.gz

    mkdir -p /usr/local/mydebs
    cp -R archives/* /usr/local/mydebs

    mkdir -p ~/bin
    cd ~/bin

    cat <<EOF > update-mydebs
#! /bin/bash
 cd /usr/local/mydebs
 dpkg-scanpackages . /dev/null | gzip -9c > Packages.gz
EOF

    chmod u+x ~/bin/update-mydebs

    echo "deb [trusted=yes] file:/usr/local/mydebs ./" | tee -a /etc/apt/sources.list

    ./update-mydebs

    apt-get update

    apt-get install -y kubelet=1.21.7-00 kubeadm=1.21.7-00 kubectl=1.21.7-00
    apt-mark hold kubelet kubeadm kubectl

    echo "Kubernetes ë²„ì „ í™•ì¸:"
    kubectl version --client
    kubeadm version
    kubelet --version

    echo "Kubernetes ì„¤ì¹˜ ì™„ë£Œ"
}

setup_master_node() {
    echo "====================> Master Node ì„¤ì • ì¤‘..."
    # init
    kubeadm config images list
    kubeadm config images pull

    # Flannel 10.244.0.0/16 ì‚¬ìš©
    kubeadm init --pod-network-cidr=10.244.0.0/16 --node-name xsailor-master

    # ì‹¤ì œ ì¼ë°˜ ì‚¬ìš©ì í™•ì¸ (logname ëª…ë ¹ì´ ì‹¤íŒ¨í•˜ëŠ” ê²½ìš° ëŒ€ë¹„)
    if NORMAL_USER=$(logname 2>/dev/null); then
        echo "ì¼ë°˜ ì‚¬ìš©ì: $NORMAL_USER"
    else
        # logname ì‹¤íŒ¨ì‹œ sudoë¥¼ ì‹¤í–‰í•œ ì‹¤ì œ ì‚¬ìš©ì ì°¾ê¸°
        NORMAL_USER=$(who am i | awk '{print $1}')
        if [ -z "$NORMAL_USER" ]; then
            # ê·¸ë˜ë„ ì‹¤íŒ¨í•˜ë©´ /home ë””ë ‰í† ë¦¬ ë‚´ì˜ ì²« ë²ˆì§¸ ì¼ë°˜ ì‚¬ìš©ì ì‚¬ìš©
            NORMAL_USER=$(find /home -mindepth 1 -maxdepth 1 -type d -printf "%f\n" | grep -v "lost+found" | head -n 1)
        fi
        echo "ì¼ë°˜ ì‚¬ìš©ì ê°ì§€: $NORMAL_USER"
    fi

    USER_HOME="/home/$NORMAL_USER"

    # root ì‚¬ìš©ììš© kubeconfig ì„¤ì •
    echo "root ì‚¬ìš©ì kubeconfig ì„¤ì •..."
    mkdir -p /root/.kube
    cp -f /etc/kubernetes/admin.conf /root/.kube/config
    chown root:root /root/.kube/config
    export KUBECONFIG=/root/.kube/config

    # ì¼ë°˜ ì‚¬ìš©ììš© kubeconfig ì„¤ì •
    echo "ì¼ë°˜ ì‚¬ìš©ì kubeconfig ì„¤ì •..."
    mkdir -p $USER_HOME/.kube
    cp -f /etc/kubernetes/admin.conf $USER_HOME/.kube/config
    chown -R $NORMAL_USER:$NORMAL_USER $USER_HOME/.kube

    # í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (.bashrcì— ì¶”ê°€)
    echo 'export KUBECONFIG=$HOME/.kube/config' >> $USER_HOME/.bashrc

    # ì¤‘ìš”: ê³µìœ  ìŠ¤í† ë¦¬ì§€ì— config íŒŒì¼ ë³µì‚¬
    mkdir -p $USER_HOME/tethys-v
    cp -f /etc/kubernetes/admin.conf $USER_HOME/tethys-v/config
    chown -R $NORMAL_USER:$NORMAL_USER $USER_HOME/tethys-v

    echo "ë§ˆìŠ¤í„° ë…¸ë“œ kubeconfigë¥¼ ê³µìœ  ìŠ¤í† ë¦¬ì§€ì— ë³µì‚¬í–ˆìŠµë‹ˆë‹¤: ~/tethys-v/config"

    # Join í† í° ìƒì„± ë° ì¶œë ¥
    echo -e "\nì›Œì»¤ ë…¸ë“œ ì¡°ì¸ ëª…ë ¹ì–´ ì •ë³´:"
    JOIN_TOKEN=$(kubeadm token create)
    HASH=$(openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2>/dev/null | openssl dgst -sha256 -hex | sed 's/^.* //')

    # ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ê°€ eno1ì´ ì•„ë‹ ê²½ìš° ëŒ€ë¹„
    if ip -4 addr show eno1 >/dev/null 2>&1; then
        IP_ADDRESS=$(ip -4 addr show eno1 | grep -oP '(?<=inet\s)\d+(\.\d+){3}')
    else
        # ë‹¤ë¥¸ ì¸í„°í˜ì´ìŠ¤ì—ì„œ IPv4 ì£¼ì†Œ ì°¾ê¸°
        IP_ADDRESS=$(ip -4 addr show | grep -v '127.0.0.1' | grep -oP '(?<=inet\s)\d+(\.\d+){3}' | head -n 1)
    fi

    echo -e "\në‹¤ìŒ ëª…ë ¹ì–´ë¥¼ ì›Œì»¤ ë…¸ë“œì—ì„œ ì‹¤í–‰í•˜ì„¸ìš”:\n"
    echo "sudo kubeadm join ${IP_ADDRESS}:6443 --token ${JOIN_TOKEN} --discovery-token-ca-cert-hash sha256:${HASH} --node-name xsailor-worker1"

    # ì„¤ì •ì„ íŒŒì¼ë¡œ ì €ì¥
    JOIN_COMMAND="sudo kubeadm join ${IP_ADDRESS}:6443 --token ${JOIN_TOKEN} --discovery-token-ca-cert-hash sha256:${HASH} --node-name xsailor-worker1"
    echo "$JOIN_COMMAND" > $USER_HOME/worker_join_command.txt
    chown $NORMAL_USER:$NORMAL_USER $USER_HOME/worker_join_command.txt
    echo "$JOIN_COMMAND" > /root/worker_join_command.txt  # root ì‚¬ìš©ìë¥¼ ìœ„í•œ ë³µì‚¬ë³¸

    # Flannel ë„¤íŠ¸ì›Œí¬ ì„¤ì¹˜
    echo "Flannel ë„¤íŠ¸ì›Œí¬ ì„¤ì¹˜ ì¤‘..."
    # root ê¶Œí•œìœ¼ë¡œ ì§ì ‘ ì‹¤í–‰
    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

    # ë§ˆìŠ¤í„° ë…¸ë“œ taint ì œê±° (ëª¨ë“  ë…¸ë“œì—ì„œ íŒŒë“œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡)
    kubectl taint nodes --all node-role.kubernetes.io/master- || true

    echo "Kubernetes ë…¸ë“œ ìƒíƒœ:"
    kubectl get nodes

    echo "Master Node ì„¤ì • ì™„ë£Œ"
}
setup_worker_node() {
    echo "====================> Worker Node ì„¤ì • ì¤‘..."
    # ì¼ë°˜ ì‚¬ìš©ì í™•ì¸
    NORMAL_USER=$(logname)
    USER_HOME="/home/$NORMAL_USER"

    # ì¤‘ìš”: ê³µìœ  ìŠ¤í† ë¦¬ì§€ì—ì„œ config íŒŒì¼ ê°€ì ¸ì˜¤ê¸°
    mkdir -p $USER_HOME/.kube

    # tethys-vëŠ” ì´ë¯¸ ê³µìœ  ìŠ¤í† ë¦¬ì§€ë¡œ ë§ˆìš´íŠ¸ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
    mkdir -p $HOME/.kube
    cp ~/tethys-v/config ~/.kube/config
    sudo chown $(id -u):$(id -g) $HOME/.kube/config

    # Join ëª…ë ¹ì–´ ì•ˆë‚´
    echo -e "\në§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì¶œë ¥ëœ join ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
    echo "ì˜ˆì‹œ: sudo kubeadm join 10.19.86.137:6443 \\"
    echo "--token wgd07r.bf72vojha3okou4d \\"
    echo "--discovery-token-ca-cert-hash sha256:ada3674485d5535aecad9ac1f2117dac3334a3e9d82822f30314b29d24007ec5 \\"
    echo "--node-name xsailor-worker1"

    echo "Worker Node ì„¤ì • ì•ˆë‚´ ì™„ë£Œ"
}

install_flannel() {
    echo "====================> Flannel ì„¤ì¹˜ ì¤‘..."
    # logname ëŒ€ì‹  ì§ì ‘ kubectl ì‚¬ìš©
    kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml

    # ë…¸ë“œ ìƒíƒœ í™•ì¸
    echo -e "\në…¸ë“œ ìƒíƒœ í™•ì¸:"
    kubectl get nodes

    # ë§ˆìŠ¤í„° ë…¸ë“œ taint ì œê±° (ëª¨ë“  ë…¸ë“œì—ì„œ íŒŒë“œ ì‹¤í–‰ ê°€ëŠ¥í•˜ë„ë¡)
    kubectl taint nodes --all node-role.kubernetes.io/master- || true

    echo -e "\nFlannel ì„¤ì¹˜ ì™„ë£Œ"
}

install_nvidia_device_plugin() {
    echo "====================> NVIDIA device plugin ì„¤ì¹˜ ì¤‘..."
    # ì§ì ‘ kubectl ì‚¬ìš©
    kubectl create -f https://raw.githubusercontent.com/NVIDIA/k8s-device-plugin/v0.10.0/nvidia-device-plugin.yml

    # ë…¸ë“œ ê°œìˆ˜ë§Œí¼ podê°€ ìˆëŠ”ì§€ í™•ì¸
    echo -e "\nNVIDIA device plugin pods:"
    kubectl get pod -n kube-system | grep nvidia

    # ê° ë…¸ë“œë³„ GPU ê°œìˆ˜ í™•ì¸
    echo -e "\nê° ë…¸ë“œë³„ GPU ê°œìˆ˜:"
    kubectl get nodes "-o=custom-columns=NAME:.metadata.name,GPU:.status.allocatable.nvidia\.com/gpu"

    echo -e "\nNVIDIA device plugin ì„¤ì¹˜ ì™„ë£Œ"
}

fix_gpu_issues() {
    echo "====================> GPU ë¬¸ì œ í•´ê²° ì¤‘..."
    # GPUê°€ <none>ìœ¼ë¡œ í‘œì‹œë˜ëŠ” ê²½ìš°
    cat <<EOF | tee /etc/docker/daemon.json
{
    "default-runtime": "nvidia",
    "runtimes": {
        "nvidia": {
            "path": "nvidia-container-runtime",
            "runtimeArgs": []
        }
    }
}
EOF

    # Docker ì„œë¹„ìŠ¤ ì¬ì‹œì‘
    systemctl restart docker

    echo "Docker ì„¤ì • ë³€ê²½ ë° ì¬ì‹œì‘ ì™„ë£Œ. GPU ìƒíƒœê°€ ì—…ë°ì´íŠ¸ë˜ëŠ” ë° ëª‡ ë¶„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
}

setup_node_selector() {
    echo "====================> Node selector ì„¤ì • ì¤‘..."
    kubectl label nodes xsailor-master twonode=worker || true
    kubectl label nodes xsailor-worker1 twonode=worker || true

    echo "Node selector ì„¤ì • ì™„ë£Œ"
}

install_training_operator() {
    echo "====================> Training Operator ì„¤ì¹˜ ì¤‘..."
    kubectl apply -k "github.com/kubeflow/training-operator/manifests/overlays/standalone?ref=v1.7.0"

    echo "Training Operator ì„¤ì¹˜ ì™„ë£Œ"
}

setup_pv_pvc() {
    echo "====================> PV, PVC ì„¤ì • ì¤‘..."
    cd /home/tensorspot/Cloud-init

    kubectl create -f /home/tensorspot/Cloud-init/tfjob-data-volume.yaml
    kubectl create -f /home/tensorspot/Cloud-init/tfjob-nfs-dataset-storage-volume.yaml

    echo "PV, PVC ì„¤ì • ì™„ë£Œ"
}

pull_docker_images() { # ì–‘ ìª½ ë…¸ë“œ ëª¨ë‘ì—ì„œ ì‹¤í–‰
    echo "====================> Docker ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘..."
    docker pull potato4332/tf2-cpu-docker:0.5.5x
    docker pull potato4332/tf2-gpu-docker:0.4.5x
    docker pull potato4332/nlp-keras:0.0.1x

    echo "Docker ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ"
}

setup_bandwidth_limit() {
    echo "====================> ëŒ€ì—­í­ ì œí•œ ì„¤ì • ì¤‘..."
    # í˜„ì¬ tc ìƒíƒœ í™•ì¸
    sh /home/tensorspot/Cloud-init/eno1_tc_10G.sh show

    # tc ì‹œì‘ (ëŒ€ì—­í­ ì œí•œ ì‹œì‘)
    sh /home/tensorspot/Cloud-init/eno1_tc_10G.sh start

    echo "ëŒ€ì—­í­ ì œí•œ ì„¤ì • ì™„ë£Œ"
}

setup_iperf() {
    echo "====================> iperf ì„¤ì • ì¤‘..."
    cd /home/tensorspot/Cloud-init

    kubectl create -f /home/tensorspot/Cloud-init/iperf.yaml

    echo "iperf ì„œë²„ íŒŒë“œ ì •ë³´:"
    kubectl get pods | grep iperf

    echo -e "\nì„œë²„ íŒŒë“œì— ì ‘ì†í•˜ì—¬ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰: /usr/bin/iperf3 -s -p 5202"
    echo "í´ë¼ì´ì–¸íŠ¸ íŒŒë“œì— ì ‘ì†í•˜ì—¬ ë‹¤ìŒ ëª…ë ¹ì–´ ì‹¤í–‰: /usr/bin/iperf3 -c [ì„œë²„íŒŒë“œIP] -p 5202 -P 32 -t 10"
    echo -e "\n(íŒŒë“œì— ì ‘ì†í•˜ë ¤ë©´: kubectl exec -it [pod-name] -- /bin/bash)"
    echo -e "\níŒŒë“œ IP í™•ì¸ ë°©ë²•: kubectl get pods -o wide"

    echo "iperf ì„¤ì • ì™„ë£Œ"
}

# ê³µí†µ ì„¤ì¹˜ ê³¼ì •
common_setup() {
    install_cuda
    install_cudnn
    install_docker
    install_nvidia_docker
    setup_prerequisites
    install_kubernetes
    pull_docker_images
    setup_bandwidth_limit
}

if [[ "$NODE_TYPE" == "master" ]]; then
    echo "ë§ˆìŠ¤í„° ë…¸ë“œ ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
    common_setup
    setup_master_node  # de í•¨ìˆ˜ ëŒ€ì‹  setup_master_node ì‚¬ìš©
    # ì´ë¯¸ setup_master_nodeì—ì„œ flannelì„ ì„¤ì¹˜í–ˆìœ¼ë¯€ë¡œ ì•„ë˜ ë¼ì¸ì€ ì„ íƒì ìœ¼ë¡œ ì£¼ì„ ì²˜ë¦¬
    # install_flannel
    install_nvidia_device_plugin
    fix_gpu_issues
    setup_node_selector
    install_training_operator
    setup_pv_pvc
    setup_iperf
    echo "ë§ˆìŠ¤í„° ë…¸ë“œ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    echo "ì›Œì»¤ ë…¸ë“œ ì¡°ì¸ ëª…ë ¹ì–´ë¥¼ í™•ì¸í•˜ì„¸ìš”: ~/worker_join_command.txt"
fi

# ì›Œì»¤ ë…¸ë“œ ì„¤ì •
if [[ "$NODE_TYPE" == "worker" ]]; then
    echo "ì›Œì»¤ ë…¸ë“œ ì„¤ì •ì„ ì‹œì‘í•©ë‹ˆë‹¤..."
    common_setup
    setup_worker_node
    fix_gpu_issues
    echo "ì›Œì»¤ ë…¸ë“œ ì„¤ì •ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤."
    echo "ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì œê³µí•œ join ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”."
fi

echo "================= Lambda Labs Setup ì™„ë£Œ ================="
